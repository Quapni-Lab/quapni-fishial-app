import cv2
import supervision as sv
from inference import get_model
import streamlit as st
from PIL import Image
import numpy as np
# import googletrans
## classification_task
import os
import cv2
os.environ['KMP_DUPLICATE_LIB_OK']='True'
from classification_task.inference_class import EmbeddingClassifier
from pathlib import Path

class YoloDetector:
    """YOLO æª¢æ¸¬å™¨é¡åˆ¥ï¼Œå°è£äº†åœ–åƒè™•ç†å’Œæª¢æ¸¬çš„ä¸»è¦æ–¹æ³•ã€‚

    Attributes:
        model: YOLO æ¨¡å‹ï¼Œç”¨æ–¼é€²è¡Œç‰©é«”æª¢æ¸¬ã€‚
    """

    def __init__(self, model_id, api_key):
        """
        åˆå§‹åŒ– YoloDetector ç‰©ä»¶ã€‚

        Args:
            model_id (str): æ¨¡å‹ IDã€‚
            api_key (str): API é‡‘é‘°ã€‚
        """
        self.model = get_model(model_id=model_id, api_key=api_key)

    def load_image(self, uploaded_file):
        """
        å¾ä¸Šå‚³çš„æ–‡ä»¶ä¸­è®€å–åœ–åƒã€‚

        Args:
            uploaded_file: ä¸Šå‚³çš„åœ–åƒæ–‡ä»¶ã€‚

        Returns:
            numpy.ndarray: è®€å–çš„åœ–åƒã€‚
        """
        file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
        image = cv2.imdecode(file_bytes, 1)
        return image

    def resize_image(self, image, target_width=640):
        """
        å°‡åœ–åƒç­‰æ¯”ä¾‹ç¸®æ”¾åˆ°æŒ‡å®šå¯¬åº¦ã€‚

        Args:
            image (numpy.ndarray): åŸå§‹åœ–åƒã€‚
            target_width (int, optional): ç›®æ¨™å¯¬åº¦ã€‚é»˜èªç‚º 640ã€‚

        Returns:
            numpy.ndarray: ç¸®æ”¾å¾Œçš„åœ–åƒã€‚
        """
        original_height, original_width = image.shape[:2]
        scale_ratio = target_width / original_width
        target_height = int(original_height * scale_ratio)
        resized_image = cv2.resize(image, (target_width, target_height))
        return resized_image

    def run_inference(self, image):
        """
        åŸ·è¡Œæ¨¡å‹æ¨è«–ï¼Œæª¢æ¸¬åœ–åƒä¸­çš„ç‰©é«”ã€‚

        Args:
            image (numpy.ndarray): è¼¸å…¥åœ–åƒã€‚

        Returns:
            supervision.Detections: æª¢æ¸¬çµæœã€‚
        """
        result = self.model.infer(image, confidence=0.1)[0]
        detections = sv.Detections.from_inference(result)
        return detections

    def get_max_confidence_detection(self, detections):
        """
        å¾æª¢æ¸¬çµæœä¸­æ‰¾åˆ°æœ€å¤§ç½®ä¿¡åº¦çš„ç‰©é«”ã€‚

        Args:
            detections (supervision.Detections): æª¢æ¸¬çµæœã€‚

        Returns:
            supervision.Detections: åŒ…å«æœ€å¤§ç½®ä¿¡åº¦ç‰©é«”çš„æª¢æ¸¬çµæœã€‚
        """
        if len(detections.xyxy) > 1:
            max_confidence_index = detections.confidence.argmax()
            max_detection_xyxy = detections.xyxy[max_confidence_index].reshape(1, -1)
            max_detection_confidence = detections.confidence[max_confidence_index:max_confidence_index+1]
            max_detection_class_id = detections.class_id[max_confidence_index:max_confidence_index+1]
            max_detection_data = {key: value[max_confidence_index:max_confidence_index+1] for key, value in detections.data.items()}
            detections = sv.Detections(
                xyxy=max_detection_xyxy,
                confidence=max_detection_confidence,
                class_id=max_detection_class_id,
                data=max_detection_data
            )
        return detections

    def add_confidence_to_label(self, detections):
        """
        å°‡ç½®ä¿¡åº¦æ·»åŠ åˆ°æ¨™ç±¤ä¸­ã€‚

        Args:
            detections (supervision.Detections): æª¢æ¸¬çµæœã€‚

        Returns:
            list: æ¨™ç±¤åˆ—è¡¨ï¼ŒåŒ…å«ç½®ä¿¡åº¦ä¿¡æ¯ã€‚
        """
        labels = []
        for i in range(len(detections.xyxy)):
            class_name = detections.data['class_name'][i]
            confidence = detections.confidence[i]
            label = f"Fish {confidence*100:.0f}%"
            labels.append(label)
        return labels

    def annotate_image(self, image, detections, labels):
        """
        æ¨™è¨»åœ–åƒï¼Œé¡¯ç¤ºæª¢æ¸¬åˆ°çš„ç‰©é«”å’Œç½®ä¿¡åº¦ã€‚

        Args:
            image (numpy.ndarray): è¼¸å…¥åœ–åƒã€‚
            detections (supervision.Detections): æª¢æ¸¬çµæœã€‚
            labels (list): æ¨™ç±¤åˆ—è¡¨ã€‚

        Returns:
            numpy.ndarray: æ¨™è¨»å¾Œçš„åœ–åƒã€‚
        """
        label_annotator = sv.LabelAnnotator(text_color=sv.Color.WHITE, text_position=sv.Position.TOP_CENTER, color=sv.Color(r=251, g=81, b=163))
        corner_annotator = sv.BoxCornerAnnotator(color=sv.Color(r=251, g=81, b=163))

        annotated_image = image.copy()
        annotated_image = corner_annotator.annotate(scene=annotated_image, detections=detections)
        annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections, labels=labels)
        return annotated_image
    
class ResNetClassifier:
    """ResNet åˆ†é¡å™¨ï¼Œç”¨æ–¼åœ–åƒä¸­çš„é­šç¨®è¾¨è­˜ã€‚"""

    def __init__(self, model_folder='classification_task/model', device='cpu'):
        """
        åˆå§‹åŒ– ResNet åˆ†é¡å™¨ã€‚

        Args:
            model_folder (str): å­˜æ”¾æ¨¡å‹æ–‡ä»¶çš„æ–‡ä»¶å¤¾è·¯å¾‘ã€‚
            device (str): é‹è¡Œæ¨¡å‹çš„è¨­å‚™ ('cpu' æˆ– 'cuda')ã€‚
        """
        # model = Path("embeddings.pt")
        # if not model.exists():
        #     with st.spinner("Downloading model... this may take awhile! \n Don't stop it!"):
        #         from GD_download import download_file_from_google_drive
        #         download_file_from_google_drive("19lLNWnZs8iMibYHR_3t86VYq7Z1vgxEF", model)
        # model2 = Path("model.ts")
        # if not model2.exists():
        #     with st.spinner("Downloading model2... this may take awhile! \n Don't stop it!"):
        #         from GD_download import download_file_from_google_drive
        #         download_file_from_google_drive("1y4lkJZC97vo9XX7xpq0KvdVZJCF-oRG_", model2)
        # model3 = Path("idx.json")
        # if not model3.exists():
        #     with st.spinner("Downloading model3... this may take awhile! \n Don't stop it!"):
        #         from GD_download import download_file_from_google_drive
        #         download_file_from_google_drive("1Rtsr8mp85SO5g-joyVXo3qNbFndKi748", model3)
        self.classification_path = os.path.join(model_folder, 'model.ts')
        self.data_base_path = os.path.join(model_folder, 'embeddings.pt')
        self.data_idx_path = os.path.join(model_folder, 'idx.json')
        self.device = device
        self.model = EmbeddingClassifier(
            self.classification_path,
            self.data_base_path,
            self.data_idx_path,
            # 'model.ts',
            # 'embeddings.pt',
            # 'idx.json',
            device=self.device
        )

    def classify_image(self, image):
        """
        å°å–®ä¸€åœ–åƒé€²è¡Œé­šç¨®è¾¨è­˜ã€‚

        Args:
            image (numpy array): è¦é€²è¡Œè¾¨è­˜çš„åœ–åƒã€‚

        Returns:
            list of dict: è¾¨è­˜çµæœåˆ—è¡¨ï¼ŒåŒ…å«é­šç¨®åç¨±å’Œç½®ä¿¡åº¦ã€‚
        """
        single_output = self.model.inference_numpy(image)
        classifier_results = []
        for item in single_output:
            fish_id = item[0]
            fish_info = item[1]
            fish_name = fish_info[0]
            fish_confidence = fish_info[1]
            classifier_results.append({"name": fish_name, "confidence": fish_confidence})
        return classifier_results

def crop_max_detection(image, detections):
    """
    è£å‰ªåœ–åƒä¸­æœ€å¤§ç½®ä¿¡åº¦çš„ç‰©é«”ã€‚

    Args:
        image (numpy.ndarray): è¼¸å…¥åœ–åƒã€‚
        detections (supervision.Detections): æª¢æ¸¬çµæœã€‚

    Returns:
        numpy.ndarray: è£å‰ªå¾Œçš„åœ–åƒï¼Œæˆ– None å¦‚æœæ²’æœ‰æª¢æ¸¬åˆ°ç‰©é«”ã€‚
    """
    if len(detections.xyxy) > 0:
        x1, y1, x2, y2 = map(int, detections.xyxy[0])
        cropped_image = image[y1:y2, x1:x2]
        return cropped_image
    return None

def display_results(results, cropped_image):
    """
    é¡¯ç¤ºåˆ†é¡çµæœå’Œè£å‰ªå¾Œçš„åœ–åƒã€‚

    Args:
        results (list): åˆ†é¡çµæœåˆ—è¡¨ã€‚
        cropped_image (numpy.ndarray): è£å‰ªå¾Œçš„åœ–åƒã€‚
    """
    st.markdown('#### åˆ†æçµæœ')
    table_col1, table_col2 = st.columns([3, 1])
    with table_col1:
        for result in results:
            col1, col2, col3 = st.columns([3, 1, 3])

            with col1:
                if result["name"] == 'Pogonias cromis':
                    st.subheader('é»‘é¯›') # é¡¯ç¤ºä¸­æ–‡åç¨±
                elif result["name"] == 'Trachinotus falcatus':
                    st.subheader('é‡‘é¯§é­š') # é¡¯ç¤ºä¸­æ–‡åç¨±
                # else:
                #     translator = googletrans.Translator() # googleç¿»è­¯
                #     translation = translator.translate(result["name"], dest='zh-tw') # ç¿»è­¯æˆç¹é«”ä¸­æ–‡
                #     st.subheader(translation.text) # é¡¯ç¤ºä¸­æ–‡åç¨±
                st.caption(result["name"]) #é¡¯ç¤ºè‹±æ–‡åç¨±

            with col2:
                st.write("\n\n")
                st.write(f"{result['confidence'] * 100:.1f}%")

            with col3:
                st.write("\n\n")
                st.progress(result["confidence"])

    if cropped_image is not None:
        with table_col2:
            st.image(cropped_image[:,:,::-1])

def process_and_display_example_image(image_path, detector, classifier):
    image = cv2.imread(image_path)
    resized_image = detector.resize_image(image)
    detections = detector.run_inference(resized_image)
    detections = detector.get_max_confidence_detection(detections)
    labels = detector.add_confidence_to_label(detections)
    annotated_image = detector.annotate_image(resized_image, detections, labels)
    st.image(annotated_image[:,:,::-1], caption='Annotated Image')
    cropped_image = crop_max_detection(resized_image, detections)
    if cropped_image is not None:
        classifier_results = classifier.classify_image(cropped_image)
        # st.write("Classification Results:", classifier_results)
        display_results(classifier_results, cropped_image)
        st.toast('è¾¨è­˜æˆåŠŸ!', icon='ğŸ‰')
    else:
        st.error("æœªåœ¨åœ–ç‰‡ä¸­æ‰¾åˆ°å¯è­˜åˆ¥çš„é­šé¡" ,icon="ğŸš¨")

def main():
    """ä¸»å‡½æ•¸ï¼ŒåŸ·è¡Œ Streamlit æ‡‰ç”¨ç¨‹å¼ã€‚"""
    st.title("Quapni Fish Detection App")
    st.caption("ä¸Šå‚³ä¸€å¼µåœ–ç‰‡ï¼Œè­˜åˆ¥é­šçš„ç¨®é¡")
    
    model_id = "fish-ku7kf/1"
    api_key = 'ZAlitxVtkbZWqNvDDxOw'
    # api_key = st.secrets["roboflow_api_key"]
    detector = YoloDetector(model_id, api_key)
    classifier = ResNetClassifier(model_folder='classification_task/model')

    tab1, tab2 = st.tabs(["â¬†ï¸ ä¸Šå‚³åœ–ç‰‡", "ğŸ–¼ï¸ Example"])
    with tab1:
        uploaded_file = st.file_uploader("**ä¸Šå‚³åœ–ç‰‡**", type=['png', 'jpeg', 'jpg'])
        if uploaded_file is not None:
            with st.spinner(text='Loading...'):
                image = detector.load_image(uploaded_file)
                resized_image = detector.resize_image(image)
                # YOLOç‰©ä»¶è¾¨è­˜
                detections = detector.run_inference(resized_image)
                detections = detector.get_max_confidence_detection(detections)
                labels = detector.add_confidence_to_label(detections)
                annotated_image = detector.annotate_image(resized_image, detections, labels)
                st.image(annotated_image[:,:,::-1])
                # ç‰©ä»¶å‰ªè£
                cropped_image = crop_max_detection(resized_image, detections) 
                if cropped_image is not None:
                    # ResNeté­šç¨®åˆ†é¡
                    classifier_results = classifier.classify_image(cropped_image)
                    # st.write("Classification Results:", classifier_results)
                    display_results(classifier_results, cropped_image)
                    st.toast('è¾¨è­˜æˆåŠŸ!', icon='ğŸ‰')
                else:
                    st.error("æœªåœ¨åœ–ç‰‡ä¸­æ‰¾åˆ°å¯è­˜åˆ¥çš„é­šé¡" ,icon="ğŸš¨")
                
        with tab2:
            example_col1, example_col2, example_col3 = st.columns(3)
            example_col1.image('example/é»‘é¯›.jpg')
            example_col2.image('example/å³éƒ­é­š.jpg')
            example_col3.image('example/é‡‘é¯§é­š.png')
            if example_col1.button('è¾¨è­˜æ­¤é­š', key=1):
                process_and_display_example_image('example/é»‘é¯›.jpg', detector, classifier)
            if example_col2.button('è¾¨è­˜æ­¤é­š', key=2):
                process_and_display_example_image('example/å³éƒ­é­š.jpg', detector, classifier)
            if example_col3.button('è¾¨è­˜æ­¤é­š', key=3):
                process_and_display_example_image('example/é‡‘é¯§é­š.png', detector, classifier)

if __name__ == '__main__':
    main()
